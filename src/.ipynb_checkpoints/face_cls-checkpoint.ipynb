{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82a16333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, random_split,RandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import MNIST, EMNIST\n",
    "import torch.nn.functional as F\n",
    "from matplotlib.pyplot import subplots\n",
    "from torchvision.utils import save_image\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "bs = 128\n",
    "n_epoch = 50\n",
    "dim=100\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "writer = SummaryWriter(os.path.join('../celeimg', 'raw_test_moredata'))\n",
    "gpu = 0\n",
    "device = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d59ae533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference(net, testloader):\n",
    "    \"\"\" Returns the test accuracy and loss.\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    loss, total, correct = 0.0, 0.0, 0.0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    criterion.cuda(gpu)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(testloader):\n",
    "            images, labels = images.cuda(gpu), labels.cuda(gpu)\n",
    "            \n",
    "            # Inference\n",
    "            outputs = net(images).squeeze()\n",
    "            batch_loss = criterion(outputs, labels)\n",
    "            loss += copy.deepcopy(batch_loss.item())\n",
    "\n",
    "            # Prediction\n",
    "            _, pred_labels = torch.max(outputs, 1)\n",
    "            pred_labels = pred_labels.view(-1)\n",
    "            correct += torch.sum(torch.eq(pred_labels, labels)).item()\n",
    "            total += len(labels)\n",
    "    accuracy = correct/total\n",
    "    return accuracy, loss\n",
    "\n",
    "class generator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, d=128):\n",
    "        super(generator, self).__init__()\n",
    "        self.deconv1 = nn.ConvTranspose2d(100, d*8, 4, 1, 0)\n",
    "        self.deconv1_bn = nn.BatchNorm2d(d*8)\n",
    "        self.deconv2 = nn.ConvTranspose2d(d*8, d*4, 4, 2, 1)\n",
    "        self.deconv2_bn = nn.BatchNorm2d(d*4)\n",
    "        self.deconv3 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)\n",
    "        self.deconv3_bn = nn.BatchNorm2d(d*2)\n",
    "        self.deconv4 = nn.ConvTranspose2d(d*2, d, 4, 2, 1)\n",
    "        self.deconv4_bn = nn.BatchNorm2d(d)\n",
    "        self.deconv5 = nn.ConvTranspose2d(d, 3, 4, 2, 1)\n",
    "\n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        # x = F.relu(self.deconv1(input))\n",
    "        x = F.relu(self.deconv1_bn(self.deconv1(input)))\n",
    "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
    "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
    "        x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
    "        x = F.tanh(self.deconv5(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, d=128):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, d, 4, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(d*2)\n",
    "        self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(d*4)\n",
    "        self.conv4 = nn.Conv2d(d*4, d*8, 4, 2, 1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(d*8)\n",
    "        self.conv5 = nn.Conv2d(d*8, 5, 4, 1, 0)# 1-6\n",
    "        #self.linear = nn.Linear(16384, 6)\n",
    "\n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        x = F.leaky_relu(self.conv1(input), 0.2)\n",
    "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n",
    "        #print(x.size())\n",
    "        x = self.conv5(x)\n",
    "        #print(x.size())\n",
    "        #x = F.sigmoid(self.conv5(x))\n",
    "        #x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e95a3113",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7496/516426455.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mpri_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpri_y\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mpri_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpri_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpri_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpri_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \"\"\"\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input tensor should be a torch tensor. Got {}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input tensor should be a float tensor. Got {}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "img_size = 64\n",
    "isCrop = False\n",
    "if isCrop:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Scale(108),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "else:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "data_dir = '../face_5cls'          # this path depends on your computer\n",
    "dset = datasets.ImageFolder(data_dir, transform)\n",
    "train_size = int(0.8 * len(dset))\n",
    "test_size = len(dset)- train_size\n",
    "train_set, test_set = random_split(dset, [train_size, test_size])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=bs,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=100,shuffle=False)\n",
    "\n",
    "lr = 0.0002\n",
    "#G = generator(128)\n",
    "D = discriminator(128)\n",
    "#G.weight_init(mean=0.0, std=0.02)\n",
    "D.weight_init(mean=0.0, std=0.02)\n",
    "#G.cuda(gpu)\n",
    "D.cuda(gpu)\n",
    "\n",
    "#criterion = nn.BCELoss().cuda(gpu)\n",
    "criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "# Adam optimizer\n",
    "#G_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "D_optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "D.train()\n",
    "for e in range(600):\n",
    "    for pri_x, pri_y in train_loader:\n",
    "        pri_x, pri_y = pri_x.to(gpu), pri_y.to(gpu)#float\n",
    "        D.zero_grad()\n",
    "        pri_logit = D(pri_x).squeeze()\n",
    "        loss = criterion(pri_logit, pri_y)\n",
    "        loss.backward()\n",
    "        D_optimizer.step()\n",
    "    acc, loss = test_inference(D, test_loader)\n",
    "    if e % 10 == 0:\n",
    "        print(f\"Acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19dc47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 64\n",
    "isCrop = False\n",
    "if isCrop:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Scale(108),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "else:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "data_dir = '../face_5cls2'          # this path depends on your computer\n",
    "dset = datasets.ImageFolder(data_dir, transform)\n",
    "train_size = int(0.8 * len(dset))\n",
    "test_size = len(dset)- train_size\n",
    "train_set, test_set = random_split(dset, [train_size, test_size])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=bs,shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=100,shuffle=False)\n",
    "\n",
    "lr = 0.0002\n",
    "G = generator(128)\n",
    "D = discriminator(128)\n",
    "G.weight_init(mean=0.0, std=0.02)\n",
    "D.weight_init(mean=0.0, std=0.02)\n",
    "G.cuda(gpu)\n",
    "D.cuda(gpu)\n",
    "\n",
    "#criterion = nn.BCELoss().cuda(gpu)\n",
    "criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "# Adam optimizer\n",
    "G_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "D_optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89990741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_loss: 12.651909828186035, d_loss: 0.08614993095397949\n",
      "g_loss: 13.141573905944824, d_loss: 0.09410593658685684\n",
      "g_loss: 12.755373001098633, d_loss: 0.05678945779800415\n",
      "g_loss: 14.70257568359375, d_loss: 0.03202427923679352\n",
      "g_loss: 13.602941513061523, d_loss: 0.020980823785066605\n",
      "g_loss: 12.666425704956055, d_loss: 0.057274311780929565\n",
      "g_loss: 11.074185371398926, d_loss: 0.06822703778743744\n",
      "g_loss: 12.398724555969238, d_loss: 0.07406187057495117\n",
      "g_loss: 9.684730529785156, d_loss: 0.053451575338840485\n",
      "g_loss: 13.79625129699707, d_loss: 0.03480149060487747\n",
      "g_loss: 12.9408597946167, d_loss: 0.029607467353343964\n",
      "g_loss: 7.677099227905273, d_loss: 0.05751229077577591\n",
      "g_loss: 10.913191795349121, d_loss: 0.0932043194770813\n",
      "g_loss: 18.355121612548828, d_loss: 0.044129300862550735\n",
      "g_loss: 18.08595085144043, d_loss: 0.06557323783636093\n",
      "g_loss: 17.762861251831055, d_loss: 0.035820797085762024\n",
      "g_loss: 13.495246887207031, d_loss: 0.0667744055390358\n",
      "g_loss: 12.055559158325195, d_loss: 0.04023478552699089\n",
      "g_loss: 13.937106132507324, d_loss: 0.09576242417097092\n",
      "g_loss: 13.989517211914062, d_loss: 0.03227844089269638\n",
      "g_loss: 8.67210865020752, d_loss: 0.04391361400485039\n",
      "g_loss: 11.316699981689453, d_loss: 0.026759078726172447\n",
      "g_loss: 12.639578819274902, d_loss: 0.06223389506340027\n",
      "g_loss: 11.758231163024902, d_loss: 0.044058915227651596\n",
      "g_loss: 11.215014457702637, d_loss: 0.024984335526823997\n",
      "g_loss: 10.494375228881836, d_loss: 0.07807192951440811\n",
      "g_loss: 12.03341293334961, d_loss: 0.025355836376547813\n",
      "g_loss: 14.565860748291016, d_loss: 0.037015654146671295\n",
      "g_loss: 16.816091537475586, d_loss: 0.05254985764622688\n",
      "g_loss: 17.985675811767578, d_loss: 0.07290460914373398\n",
      "g_loss: 9.051488876342773, d_loss: 0.06418334692716599\n",
      "g_loss: 7.713485240936279, d_loss: 0.05806324630975723\n",
      "g_loss: 14.094331741333008, d_loss: 0.06936687231063843\n",
      "g_loss: 19.206798553466797, d_loss: 0.05601174756884575\n",
      "g_loss: 11.421806335449219, d_loss: 0.010678060352802277\n",
      "g_loss: 11.390192985534668, d_loss: 0.019177230075001717\n",
      "g_loss: 15.093649864196777, d_loss: 0.05766167864203453\n",
      "g_loss: 11.902520179748535, d_loss: 0.06694791465997696\n",
      "g_loss: 11.150754928588867, d_loss: 0.06956063210964203\n",
      "g_loss: 13.095890998840332, d_loss: 0.024088362231850624\n",
      "g_loss: 17.99032974243164, d_loss: 0.05274103954434395\n",
      "g_loss: 15.927098274230957, d_loss: 0.050557881593704224\n",
      "g_loss: 10.346711158752441, d_loss: 0.07137422263622284\n",
      "g_loss: 12.484273910522461, d_loss: 0.03109358437359333\n",
      "g_loss: 15.985319137573242, d_loss: 0.03926203399896622\n",
      "g_loss: 13.278923034667969, d_loss: 0.05024028941988945\n",
      "g_loss: 15.740540504455566, d_loss: 0.07362457364797592\n",
      "g_loss: 15.963338851928711, d_loss: 0.05127740278840065\n",
      "g_loss: 13.282008171081543, d_loss: 0.06643491238355637\n",
      "g_loss: 15.098740577697754, d_loss: 0.059512339532375336\n",
      "g_loss: 15.606342315673828, d_loss: 0.02121862769126892\n",
      "g_loss: 14.119033813476562, d_loss: 0.04495536535978317\n",
      "g_loss: 15.544853210449219, d_loss: 0.026696551591157913\n",
      "g_loss: 15.587214469909668, d_loss: 0.043016452342271805\n",
      "g_loss: 10.394463539123535, d_loss: 0.018556537106633186\n",
      "g_loss: 13.519551277160645, d_loss: 0.03601734712719917\n",
      "g_loss: 15.04696273803711, d_loss: 0.04938412457704544\n",
      "g_loss: 15.068685531616211, d_loss: 0.06439519673585892\n",
      "g_loss: 13.285026550292969, d_loss: 0.0738215297460556\n",
      "g_loss: 12.901453971862793, d_loss: 0.0733199343085289\n",
      "g_loss: 13.483100891113281, d_loss: 0.044323209673166275\n",
      "g_loss: 10.65283203125, d_loss: 0.07985983788967133\n",
      "g_loss: 11.134166717529297, d_loss: 0.01631263457238674\n",
      "g_loss: 16.656192779541016, d_loss: 0.08677168935537338\n",
      "g_loss: 11.503154754638672, d_loss: 0.024050705134868622\n",
      "g_loss: 15.738286018371582, d_loss: 0.10433662682771683\n",
      "g_loss: 10.698281288146973, d_loss: 0.04304668679833412\n",
      "g_loss: 13.166959762573242, d_loss: 0.05721842497587204\n",
      "g_loss: 16.141536712646484, d_loss: 0.07616229355335236\n",
      "g_loss: 15.672433853149414, d_loss: 0.08877195417881012\n",
      "g_loss: 11.784626007080078, d_loss: 0.06788132339715958\n",
      "g_loss: 15.012857437133789, d_loss: 0.05999833717942238\n",
      "g_loss: 14.152066230773926, d_loss: 0.061953675001859665\n",
      "g_loss: 17.216564178466797, d_loss: 0.04616275429725647\n",
      "g_loss: 12.460046768188477, d_loss: 0.02748195081949234\n",
      "g_loss: 12.256059646606445, d_loss: 0.07035312801599503\n",
      "g_loss: 11.40540885925293, d_loss: 0.022439416497945786\n",
      "g_loss: 10.01447582244873, d_loss: 0.021406887099146843\n",
      "g_loss: 12.694214820861816, d_loss: 0.03220677003264427\n",
      "g_loss: 16.183134078979492, d_loss: 0.049482155591249466\n",
      "g_loss: 7.684638500213623, d_loss: 0.02650102786719799\n",
      "g_loss: 8.491159439086914, d_loss: 0.03093567304313183\n",
      "g_loss: 11.298048973083496, d_loss: 0.03961513936519623\n",
      "g_loss: 11.025261878967285, d_loss: 0.06995021551847458\n",
      "g_loss: 13.06562614440918, d_loss: 0.04085316136479378\n",
      "g_loss: 11.82876968383789, d_loss: 0.031553201377391815\n",
      "g_loss: 7.797537803649902, d_loss: 0.06377938389778137\n",
      "g_loss: 14.335598945617676, d_loss: 0.03817281872034073\n",
      "g_loss: 14.255304336547852, d_loss: 0.07800765335559845\n",
      "g_loss: 15.050614356994629, d_loss: 0.04342648386955261\n",
      "g_loss: 14.958087921142578, d_loss: 0.08947523683309555\n",
      "g_loss: 15.283881187438965, d_loss: 0.0381959043443203\n",
      "g_loss: 15.724380493164062, d_loss: 0.063162662088871\n",
      "g_loss: 12.447768211364746, d_loss: 0.06478861719369888\n",
      "g_loss: 14.4326171875, d_loss: 0.042413562536239624\n",
      "g_loss: 8.11912727355957, d_loss: 0.07726135849952698\n",
      "g_loss: 12.660660743713379, d_loss: 0.08516521006822586\n",
      "g_loss: 16.944196701049805, d_loss: 0.04615676403045654\n",
      "g_loss: 14.15936279296875, d_loss: 0.028667978942394257\n",
      "g_loss: 13.583598136901855, d_loss: 0.019512735307216644\n",
      "g_loss: 15.776357650756836, d_loss: 0.030741672962903976\n",
      "g_loss: 12.415413856506348, d_loss: 0.05080544576048851\n",
      "g_loss: 15.034287452697754, d_loss: 0.049735311418771744\n",
      "g_loss: 7.52728796005249, d_loss: 0.038802072405815125\n",
      "g_loss: 12.396688461303711, d_loss: 0.021520372480154037\n",
      "g_loss: 14.753851890563965, d_loss: 0.026670942083001137\n",
      "g_loss: 17.699338912963867, d_loss: 0.06779120117425919\n",
      "g_loss: 17.849489212036133, d_loss: 0.046157192438840866\n",
      "g_loss: 15.71199893951416, d_loss: 0.025791391730308533\n",
      "g_loss: 15.422852516174316, d_loss: 0.03890472650527954\n",
      "g_loss: 15.423412322998047, d_loss: 0.05247178301215172\n",
      "g_loss: 15.264037132263184, d_loss: 0.051013220101594925\n",
      "g_loss: 14.532526016235352, d_loss: 0.050192102789878845\n",
      "g_loss: 14.076234817504883, d_loss: 0.0542839877307415\n",
      "g_loss: 9.190017700195312, d_loss: 0.051601022481918335\n",
      "g_loss: 14.798752784729004, d_loss: 0.059594254940748215\n",
      "g_loss: 9.59428882598877, d_loss: 0.04917345941066742\n",
      "g_loss: 9.657502174377441, d_loss: 0.04536508396267891\n",
      "g_loss: 13.755189895629883, d_loss: 0.046081993728876114\n",
      "g_loss: 13.888381958007812, d_loss: 0.011009312234818935\n",
      "g_loss: 16.771648406982422, d_loss: 0.05410947650671005\n",
      "g_loss: 18.318586349487305, d_loss: 0.06166013702750206\n",
      "g_loss: 11.915824890136719, d_loss: 0.04148460179567337\n",
      "g_loss: 11.246902465820312, d_loss: 0.037254173308610916\n",
      "g_loss: 13.47231388092041, d_loss: 0.06974171102046967\n",
      "g_loss: 9.772579193115234, d_loss: 0.060811057686805725\n",
      "g_loss: 12.996728897094727, d_loss: 0.05497502535581589\n",
      "g_loss: 10.338615417480469, d_loss: 0.06052722409367561\n",
      "g_loss: 12.488228797912598, d_loss: 0.015230695717036724\n",
      "g_loss: 16.019372940063477, d_loss: 0.07283336669206619\n",
      "g_loss: 14.439966201782227, d_loss: 0.05807667225599289\n",
      "g_loss: 9.69873046875, d_loss: 0.05676397308707237\n",
      "g_loss: 8.921978950500488, d_loss: 0.02761903777718544\n",
      "g_loss: 10.99367618560791, d_loss: 0.08763860911130905\n",
      "g_loss: 13.758938789367676, d_loss: 0.035437408834695816\n",
      "g_loss: 17.512142181396484, d_loss: 0.049114890396595\n",
      "g_loss: 10.845335960388184, d_loss: 0.06284842640161514\n",
      "g_loss: 9.490219116210938, d_loss: 0.0619581863284111\n",
      "g_loss: 14.030518531799316, d_loss: 0.028167428448796272\n"
     ]
    }
   ],
   "source": [
    "D.train()\n",
    "G.train()\n",
    "for e in range(800, 1000):\n",
    "    for real_x, real_y in train_loader:\n",
    "        real_x, real_y = real_x.to(gpu), real_y.to(gpu)\n",
    "        G.zero_grad()\n",
    "        z = Variable(torch.randn(bs, 100)).view(-1, 100, 1, 1).to(gpu)\n",
    "        fake_x = G(z)\n",
    "        target_y = copy.deepcopy(real_y).fill_(4)\n",
    "        out = D(fake_x).squeeze()\n",
    "        g_loss = criterion(out, target_y)\n",
    "        g_loss.backward(retain_graph=True)\n",
    "        G_optimizer.step()\n",
    "    \n",
    "        D.zero_grad()\n",
    "        fake_x2 = G(z)\n",
    "        f_out = D(fake_x2).squeeze()\n",
    "        d_fake_loss = criterion(f_out, copy.deepcopy(real_y).fill_(3))\n",
    "        r_out = D(real_x).squeeze()\n",
    "        d_real_loss = criterion(r_out, real_y)\n",
    "        d_loss = d_fake_loss + d_real_loss\n",
    "        d_loss.backward()\n",
    "        D_optimizer.step()\n",
    "    if e % 1 == 0:\n",
    "        print(f\"g_loss: {g_loss.item()}, d_loss: {d_loss.item()}\")\n",
    "    with torch.no_grad():\n",
    "        test_z = Variable(torch.randn(50, 100).view(-1, 100, 1, 1).to(device))\n",
    "        generated = G(test_z)\n",
    "        \n",
    "        out0grid = torchvision.utils.make_grid(generated, nrow=50)\n",
    "        writer.add_image('images', out0grid, e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26f415c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path = r\"../f2rf/0\"\n",
    "if not os.path.isdir(new_path):\n",
    "        os.makedirs(new_path)\n",
    "for i in range(120027):\n",
    "    z = Variable(torch.randn(1, 100)).view(-1, 100, 1, 1).to(gpu)\n",
    "    fake_x = G(z)\n",
    "    toPIL = transforms.ToPILImage()\n",
    "    pic = toPIL(fake_x.squeeze())\n",
    "    pic.save(new_path + \"/fake_\" + str(i) + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de6c609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
