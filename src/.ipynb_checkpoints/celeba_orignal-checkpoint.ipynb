{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d91c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, random_split,RandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import MNIST, EMNIST\n",
    "import torch.nn.functional as F\n",
    "from matplotlib.pyplot import subplots\n",
    "from torchvision.utils import save_image\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "bs = 128\n",
    "n_epoch = 50\n",
    "dim=100\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "writer = SummaryWriter(os.path.join('../face', 'test'))\n",
    "gpu = 1\n",
    "device = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4347f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference(net, testloader):\n",
    "    \"\"\" Returns the test accuracy and loss.\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    loss, total, correct = 0.0, 0.0, 0.0\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "    criterion = nn.BCELoss().cuda(gpu)\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(testloader):\n",
    "            images, labels = images.cuda(gpu), labels.float().cuda(gpu)\n",
    "            \n",
    "            # Inference\n",
    "            outputs = net(images).squeeze()\n",
    "            batch_loss = criterion(outputs, labels)\n",
    "            loss += copy.deepcopy(batch_loss.item())\n",
    "\n",
    "            # Prediction\n",
    "            _, pred_labels = torch.max(outputs, 1)\n",
    "            pred_labels = pred_labels.view(-1)\n",
    "            correct += torch.sum(torch.eq(pred_labels, labels)).item()\n",
    "            total += len(labels)\n",
    "    accuracy = correct/total\n",
    "    return accuracy, loss\n",
    "\n",
    "class generator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, d=128):\n",
    "        super(generator, self).__init__()\n",
    "        self.deconv1 = nn.ConvTranspose2d(100, d*8, 4, 1, 0)\n",
    "        self.deconv1_bn = nn.BatchNorm2d(d*8)\n",
    "        self.deconv2 = nn.ConvTranspose2d(d*8, d*4, 4, 2, 1)\n",
    "        self.deconv2_bn = nn.BatchNorm2d(d*4)\n",
    "        self.deconv3 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)\n",
    "        self.deconv3_bn = nn.BatchNorm2d(d*2)\n",
    "        self.deconv4 = nn.ConvTranspose2d(d*2, d, 4, 2, 1)\n",
    "        self.deconv4_bn = nn.BatchNorm2d(d)\n",
    "        self.deconv5 = nn.ConvTranspose2d(d, 3, 4, 2, 1)\n",
    "\n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        # x = F.relu(self.deconv1(input))\n",
    "        x = F.relu(self.deconv1_bn(self.deconv1(input)))\n",
    "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
    "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
    "        x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
    "        x = F.tanh(self.deconv5(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, d=128):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, d, 4, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(d*2)\n",
    "        self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(d*4)\n",
    "        self.conv4 = nn.Conv2d(d*4, d*8, 4, 2, 1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(d*8)\n",
    "        self.conv5 = nn.Conv2d(d*8, 1, 4, 1, 0)# 1-6\n",
    "        #self.linear = nn.Linear(16384, 6)\n",
    "\n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        x = F.leaky_relu(self.conv1(input), 0.2)\n",
    "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n",
    "        #print(x.size())\n",
    "        #x = self.conv5(x)\n",
    "        #print(x.size())\n",
    "        x = F.sigmoid(self.conv5(x))\n",
    "        #x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "912b38cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0, len： 0\n",
      "i: 1, len： 22516\n",
      "i: 2, len： 54090\n",
      "i: 3, len： 103833\n",
      "i: 4, len： 41446\n",
      "i: 5, len： 4547\n",
      "i: 6, len： 30709\n",
      "i: 7, len： 48785\n",
      "i: 8, len： 47516\n",
      "i: 9, len： 48472\n",
      "i: 10, len： 29983\n",
      "i: 11, len： 10312\n",
      "i: 12, len： 41572\n",
      "i: 13, len： 28803\n",
      "i: 14, len： 11663\n",
      "i: 15, len： 9459\n",
      "i: 16, len： 13193\n",
      "i: 17, len： 12716\n",
      "i: 18, len： 8499\n",
      "i: 19, len： 78390\n",
      "i: 20, len： 92189\n",
      "i: 21, len： 84434\n",
      "i: 22, len： 97942\n",
      "i: 23, len： 8417\n",
      "i: 24, len： 23329\n",
      "i: 25, len： 169158\n",
      "i: 26, len： 57567\n",
      "i: 27, len： 8701\n",
      "i: 28, len： 56210\n",
      "i: 29, len： 16163\n",
      "i: 30, len： 13315\n",
      "i: 31, len： 11449\n",
      "i: 32, len： 97669\n",
      "i: 33, len： 42222\n",
      "i: 34, len： 64744\n",
      "i: 35, len： 38276\n",
      "i: 36, len： 9818\n",
      "i: 37, len： 95715\n",
      "i: 38, len： 24913\n",
      "i: 39, len： 14732\n"
     ]
    }
   ],
   "source": [
    "file = r\"../list_attr_celeba.txt\"\n",
    "count = 1\n",
    "#attr_id = [5, 9, 10, 12,18]#光头，黑色，金色，棕色，白色\n",
    "attr_id = [i for i in range(40)]\n",
    "#attr_id = [19,21]#浓状，男\n",
    "imgs = {id: [] for id in attr_id}\n",
    "with open(file, 'r') as f:\n",
    "    for line in f:\n",
    "        if count < 3:\n",
    "            count += 1\n",
    "            continue\n",
    "        else:\n",
    "            attrs = line.strip().split()\n",
    "            for id in attr_id:\n",
    "                if attrs[id]== '1':\n",
    "                    imgs[id].append(attrs[0])\n",
    "                \n",
    "for i in attr_id:\n",
    "#     if len(imgs[i]) > 10000:\n",
    "#         imgs[i] = imgs[i][0: 10000]\n",
    "    print(f\"i: {i}, len： {len(imgs[i])}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27959710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120027\n"
     ]
    }
   ],
   "source": [
    "imgs[9] = imgs[9] +imgs[10] + imgs[12]\n",
    "print(len(imgs[9]))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b09acab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "old_path = r\"../img_align_celeba\"\n",
    "new_path = r\"../f2rf\"\n",
    "resize_size = 64\n",
    "for v in imgs[9]:\n",
    "    new_dir = new_path + \"/1\"\n",
    "    if not os.path.isdir(new_dir):\n",
    "        os.makedirs(new_dir)\n",
    "    \n",
    "    new_file = os.path.join(new_dir, v)\n",
    "    old_file = os.path.join(old_path, v)\n",
    "    img = plt.imread(old_file)\n",
    "    img = resize(img, (resize_size, resize_size))\n",
    "    plt.imsave(fname=new_file, arr=img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd523b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "old_path = r\"../img_align_celeba\"\n",
    "new_path = r\"../resize_face\"\n",
    "resize_size = 64\n",
    "for k, v in imgs.items():\n",
    "    new_dir = new_path + \"/\" + str(k)\n",
    "    if not os.path.isdir(new_dir):\n",
    "        os.makedirs(new_dir)\n",
    "    for id in v:\n",
    "        new_file = os.path.join(new_dir, id)\n",
    "        old_file = os.path.join(old_path, id)\n",
    "        img = plt.imread(old_file)\n",
    "        img = resize(img, (resize_size, resize_size))\n",
    "        plt.imsave(fname=new_file, arr=img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e36e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path = r\"../resize_face\"\n",
    "celeba_data = ImageFolder(new_path)\n",
    "print(celeba_data.class_to_idx)\n",
    "plt.imshow(celeba_data[100][0])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7dadcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 64\n",
    "isCrop = False\n",
    "if isCrop:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Scale(108),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "else:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "data_dir = '../gender'          # this path depends on your computer\n",
    "dset = datasets.ImageFolder(data_dir, transform)\n",
    "#train_size = int(1 * len(dset))\n",
    "#test_size = len(dset)- train_size\n",
    "#train_set, test_set = random_split(dset, [train_size, test_size])\n",
    "train_loader = torch.utils.data.DataLoader(dset, batch_size=bs,shuffle=True, drop_last=True)\n",
    "#test_loader = torch.utils.data.DataLoader(test_set, batch_size=100,shuffle=False)\n",
    "\n",
    "lr = 0.0002\n",
    "G = generator(128)\n",
    "D = discriminator(128)\n",
    "G.weight_init(mean=0.0, std=0.02)\n",
    "D.weight_init(mean=0.0, std=0.02)\n",
    "G.cuda(gpu)\n",
    "D.cuda(gpu)\n",
    "\n",
    "criterion = nn.BCELoss().cuda(gpu)\n",
    "#criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "# Adam optimizer\n",
    "G_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "D_optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91e48002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_loss: 45.94029998779297, d_loss: 0.10446663945913315\n",
      "g_loss: 43.41081619262695, d_loss: 0.05507957190275192\n",
      "g_loss: 5.297865867614746, d_loss: 0.24964118003845215\n",
      "g_loss: 8.153556823730469, d_loss: 0.5386551022529602\n",
      "g_loss: 7.0375566482543945, d_loss: 0.19082503020763397\n",
      "g_loss: 10.747581481933594, d_loss: 0.3488556146621704\n",
      "g_loss: 12.718353271484375, d_loss: 0.03883982077240944\n",
      "g_loss: 9.247682571411133, d_loss: 0.058132000267505646\n",
      "g_loss: 11.537296295166016, d_loss: 0.10447978973388672\n",
      "g_loss: 12.640929222106934, d_loss: 0.24398629367351532\n",
      "g_loss: 10.035760879516602, d_loss: 0.39067113399505615\n",
      "g_loss: 9.106047630310059, d_loss: 0.4455471634864807\n",
      "g_loss: 11.101092338562012, d_loss: 0.09719893336296082\n",
      "g_loss: 9.832199096679688, d_loss: 0.3930404782295227\n",
      "g_loss: 9.585205078125, d_loss: 0.15564560890197754\n",
      "g_loss: 13.85742473602295, d_loss: 0.3409315049648285\n",
      "g_loss: 12.815045356750488, d_loss: 0.08092702925205231\n",
      "g_loss: 15.145621299743652, d_loss: 0.3051435351371765\n",
      "g_loss: 9.688091278076172, d_loss: 0.16980695724487305\n",
      "g_loss: 10.295886993408203, d_loss: 0.12727756798267365\n",
      "g_loss: 12.8579683303833, d_loss: 0.09181515872478485\n",
      "g_loss: 11.84350299835205, d_loss: 0.15012149512767792\n",
      "g_loss: 12.592647552490234, d_loss: 0.04694770276546478\n",
      "g_loss: 12.1368989944458, d_loss: 0.12612377107143402\n",
      "g_loss: 17.350671768188477, d_loss: 1.540834665298462\n",
      "g_loss: 13.856992721557617, d_loss: 0.059199269860982895\n",
      "g_loss: 18.678913116455078, d_loss: 2.9258530139923096\n",
      "g_loss: 13.083160400390625, d_loss: 0.05080845206975937\n",
      "g_loss: 12.635372161865234, d_loss: 0.05935649573802948\n",
      "g_loss: 13.966141700744629, d_loss: 0.012050937861204147\n",
      "g_loss: 13.630505561828613, d_loss: 0.033604271709918976\n",
      "g_loss: 15.156163215637207, d_loss: 0.14786815643310547\n",
      "g_loss: 14.525020599365234, d_loss: 0.037558019161224365\n",
      "g_loss: 15.261852264404297, d_loss: 0.0530003122985363\n",
      "g_loss: 14.561217308044434, d_loss: 0.04504672437906265\n",
      "g_loss: 14.181526184082031, d_loss: 0.09746578335762024\n",
      "g_loss: 15.150588035583496, d_loss: 0.12135887891054153\n",
      "g_loss: 13.98434829711914, d_loss: 0.15396763384342194\n",
      "g_loss: 14.661393165588379, d_loss: 0.03034297190606594\n",
      "g_loss: 15.567782402038574, d_loss: 0.0830322653055191\n",
      "g_loss: 12.633174896240234, d_loss: 0.5447344183921814\n",
      "g_loss: 12.78251838684082, d_loss: 0.07545371353626251\n",
      "g_loss: 10.587152481079102, d_loss: 0.4783858358860016\n",
      "g_loss: 16.004554748535156, d_loss: 0.01924062706530094\n",
      "g_loss: 14.92247486114502, d_loss: 0.06942688673734665\n",
      "g_loss: 14.248249053955078, d_loss: 0.04776841402053833\n",
      "g_loss: 13.873506546020508, d_loss: 0.05987503007054329\n",
      "g_loss: 13.130697250366211, d_loss: 0.06448434293270111\n",
      "g_loss: 17.182018280029297, d_loss: 0.11033336073160172\n",
      "g_loss: 15.140996932983398, d_loss: 0.07095769047737122\n",
      "g_loss: 15.677604675292969, d_loss: 0.06595318764448166\n",
      "g_loss: 15.589574813842773, d_loss: 0.016029024496674538\n",
      "g_loss: 16.45905303955078, d_loss: 0.04478772357106209\n",
      "g_loss: 17.527755737304688, d_loss: 0.008081718347966671\n",
      "g_loss: 11.686271667480469, d_loss: 0.5270465016365051\n",
      "g_loss: 12.026848793029785, d_loss: 0.38184309005737305\n",
      "g_loss: 13.811714172363281, d_loss: 0.09737850725650787\n",
      "g_loss: 16.1932373046875, d_loss: 0.030458219349384308\n",
      "g_loss: 15.416769981384277, d_loss: 0.017357833683490753\n",
      "g_loss: 15.67878532409668, d_loss: 0.016592558473348618\n",
      "g_loss: 13.979978561401367, d_loss: 0.211236372590065\n",
      "g_loss: 14.639715194702148, d_loss: 0.038761917501688004\n",
      "g_loss: 16.759376525878906, d_loss: 0.0984375923871994\n",
      "g_loss: 11.131168365478516, d_loss: 0.35756799578666687\n",
      "g_loss: 16.87006950378418, d_loss: 0.012124773114919662\n",
      "g_loss: 16.49212646484375, d_loss: 0.011708371341228485\n",
      "g_loss: 16.78180694580078, d_loss: 0.08567121624946594\n",
      "g_loss: 15.240436553955078, d_loss: 0.020785599946975708\n",
      "g_loss: 17.331388473510742, d_loss: 0.0170887541025877\n",
      "g_loss: 17.411258697509766, d_loss: 0.01981389708817005\n",
      "g_loss: 16.83133316040039, d_loss: 0.071708545088768\n",
      "g_loss: 16.54086685180664, d_loss: 0.04456842318177223\n",
      "g_loss: 17.7916316986084, d_loss: 0.030515091493725777\n",
      "g_loss: 16.918428421020508, d_loss: 0.007645731326192617\n",
      "g_loss: 15.867626190185547, d_loss: 0.034915998578071594\n",
      "g_loss: 16.633377075195312, d_loss: 0.00796825997531414\n",
      "g_loss: 17.117385864257812, d_loss: 0.008914681151509285\n",
      "g_loss: 15.800752639770508, d_loss: 0.06419543921947479\n",
      "g_loss: 16.041698455810547, d_loss: 0.10584977269172668\n",
      "g_loss: 18.262165069580078, d_loss: 0.007019874639809132\n",
      "g_loss: 16.34807586669922, d_loss: 0.0500669926404953\n",
      "g_loss: 16.6497802734375, d_loss: 0.1184781938791275\n",
      "g_loss: 15.772968292236328, d_loss: 0.02369464561343193\n",
      "g_loss: 15.644004821777344, d_loss: 0.021992426365613937\n",
      "g_loss: 15.851713180541992, d_loss: 0.01950475201010704\n",
      "g_loss: 16.43534278869629, d_loss: 0.040349796414375305\n",
      "g_loss: 18.211925506591797, d_loss: 0.14263291656970978\n",
      "g_loss: 18.03972625732422, d_loss: 0.009294554591178894\n",
      "g_loss: 16.65637969970703, d_loss: 0.010774733498692513\n",
      "g_loss: 17.978267669677734, d_loss: 0.09517736732959747\n",
      "g_loss: 17.723567962646484, d_loss: 0.050281573086977005\n",
      "g_loss: 17.09103012084961, d_loss: 0.026205914095044136\n",
      "g_loss: 16.445100784301758, d_loss: 0.07561365514993668\n",
      "g_loss: 17.56144905090332, d_loss: 0.02112729847431183\n",
      "g_loss: 19.71977996826172, d_loss: 0.009099971503019333\n",
      "g_loss: 17.751712799072266, d_loss: 0.00992606207728386\n",
      "g_loss: 17.890426635742188, d_loss: 0.007882300764322281\n",
      "g_loss: 17.924022674560547, d_loss: 0.018002379685640335\n",
      "g_loss: 15.932365417480469, d_loss: 0.018125522881746292\n",
      "g_loss: 13.784965515136719, d_loss: 0.33161744475364685\n",
      "g_loss: 16.652996063232422, d_loss: 0.005124256014823914\n",
      "g_loss: 18.494407653808594, d_loss: 0.06086891517043114\n",
      "g_loss: 15.65380859375, d_loss: 0.09026499837636948\n",
      "g_loss: 17.990276336669922, d_loss: 0.004101828671991825\n",
      "g_loss: 18.685705184936523, d_loss: 0.018724994733929634\n",
      "g_loss: 18.649402618408203, d_loss: 0.01560702733695507\n",
      "g_loss: 16.765506744384766, d_loss: 0.019285865128040314\n",
      "g_loss: 16.438365936279297, d_loss: 0.03936170041561127\n",
      "g_loss: 16.801437377929688, d_loss: 0.03636147081851959\n",
      "g_loss: 17.097476959228516, d_loss: 0.009017828851938248\n",
      "g_loss: 17.874975204467773, d_loss: 0.022438418120145798\n",
      "g_loss: 18.374622344970703, d_loss: 0.06619315594434738\n",
      "g_loss: 19.097152709960938, d_loss: 0.011814848519861698\n",
      "g_loss: 17.20134735107422, d_loss: 0.037797730416059494\n",
      "g_loss: 19.70749282836914, d_loss: 0.007193651981651783\n",
      "g_loss: 19.601802825927734, d_loss: 0.02096201479434967\n",
      "g_loss: 15.424819946289062, d_loss: 0.09482938051223755\n",
      "g_loss: 19.055526733398438, d_loss: 0.018076999112963676\n",
      "g_loss: 18.67206573486328, d_loss: 0.015932263806462288\n",
      "g_loss: 18.313358306884766, d_loss: 0.08178172260522842\n",
      "g_loss: 17.081111907958984, d_loss: 0.028628038242459297\n",
      "g_loss: 14.834680557250977, d_loss: 0.6134707927703857\n",
      "g_loss: 18.256858825683594, d_loss: 0.019513150677084923\n",
      "g_loss: 17.7109375, d_loss: 0.009986466728150845\n",
      "g_loss: 14.28030014038086, d_loss: 0.3265824317932129\n",
      "g_loss: 14.59488582611084, d_loss: 0.20656779408454895\n",
      "g_loss: 19.91780662536621, d_loss: 0.004308168310672045\n",
      "g_loss: 19.907724380493164, d_loss: 0.004096486140042543\n",
      "g_loss: 17.616466522216797, d_loss: 0.014046140015125275\n",
      "g_loss: 19.436140060424805, d_loss: 0.015989961102604866\n",
      "g_loss: 22.875568389892578, d_loss: 0.034633662551641464\n",
      "g_loss: 15.719711303710938, d_loss: 0.06765514612197876\n",
      "g_loss: 18.594772338867188, d_loss: 0.008074410259723663\n",
      "g_loss: 14.30717945098877, d_loss: 0.19044990837574005\n",
      "g_loss: 17.87760353088379, d_loss: 0.026007547974586487\n",
      "g_loss: 21.43240737915039, d_loss: 0.06162497401237488\n",
      "g_loss: 18.84650421142578, d_loss: 0.014370696619153023\n",
      "g_loss: 21.617300033569336, d_loss: 0.029196713119745255\n",
      "g_loss: 15.375664710998535, d_loss: 0.07521131634712219\n",
      "g_loss: 19.230838775634766, d_loss: 0.025202929973602295\n",
      "g_loss: 22.58468246459961, d_loss: 0.3556956946849823\n",
      "g_loss: 20.250789642333984, d_loss: 0.0022867475636303425\n",
      "g_loss: 22.878814697265625, d_loss: 0.12258891761302948\n",
      "g_loss: 18.288328170776367, d_loss: 0.004150915425270796\n",
      "g_loss: 18.94406509399414, d_loss: 0.008365130983293056\n",
      "g_loss: 18.98972511291504, d_loss: 0.00365070765838027\n",
      "g_loss: 19.214088439941406, d_loss: 0.05641043186187744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_loss: 19.286977767944336, d_loss: 0.7952597737312317\n",
      "g_loss: 17.865888595581055, d_loss: 0.032089170068502426\n",
      "g_loss: 18.130783081054688, d_loss: 0.011263146065175533\n",
      "g_loss: 19.363000869750977, d_loss: 0.011303884908556938\n",
      "g_loss: 19.15265464782715, d_loss: 0.02213161624968052\n",
      "g_loss: 17.901782989501953, d_loss: 0.06849023699760437\n",
      "g_loss: 18.458675384521484, d_loss: 0.07658348977565765\n",
      "g_loss: 19.211742401123047, d_loss: 0.057742152363061905\n",
      "g_loss: 15.169065475463867, d_loss: 0.07843942195177078\n",
      "g_loss: 15.682955741882324, d_loss: 0.037457939237356186\n",
      "g_loss: 18.24524688720703, d_loss: 0.02105460688471794\n",
      "g_loss: 19.875476837158203, d_loss: 0.008051588200032711\n",
      "g_loss: 16.938032150268555, d_loss: 0.06455309689044952\n",
      "g_loss: 20.197114944458008, d_loss: 0.017802134156227112\n",
      "g_loss: 18.52947235107422, d_loss: 0.008426690474152565\n",
      "g_loss: 17.855806350708008, d_loss: 0.008640697225928307\n",
      "g_loss: 18.057952880859375, d_loss: 0.008283882401883602\n",
      "g_loss: 19.77503204345703, d_loss: 0.03638194873929024\n",
      "g_loss: 19.575233459472656, d_loss: 0.12842129170894623\n",
      "g_loss: 19.554298400878906, d_loss: 0.14199815690517426\n",
      "g_loss: 18.494680404663086, d_loss: 0.006241087336093187\n",
      "g_loss: 17.998821258544922, d_loss: 0.027818111702799797\n",
      "g_loss: 20.130596160888672, d_loss: 0.12689489126205444\n",
      "g_loss: 18.645618438720703, d_loss: 0.03340227156877518\n",
      "g_loss: 20.596435546875, d_loss: 0.06444747745990753\n",
      "g_loss: 19.95478630065918, d_loss: 0.01810031570494175\n",
      "g_loss: 18.842742919921875, d_loss: 0.033280666917562485\n",
      "g_loss: 15.30272388458252, d_loss: 0.1476021707057953\n",
      "g_loss: 18.361616134643555, d_loss: 0.03010634146630764\n",
      "g_loss: 20.126224517822266, d_loss: 0.012968014925718307\n",
      "g_loss: 18.282115936279297, d_loss: 0.012258096598088741\n",
      "g_loss: 18.784778594970703, d_loss: 0.030775511637330055\n",
      "g_loss: 19.500892639160156, d_loss: 0.09684164077043533\n",
      "g_loss: 19.903244018554688, d_loss: 0.008455993607640266\n",
      "g_loss: 20.852214813232422, d_loss: 0.00404489366337657\n",
      "g_loss: 18.73625373840332, d_loss: 0.027541404590010643\n",
      "g_loss: 20.84720230102539, d_loss: 0.0014073769561946392\n",
      "g_loss: 20.153709411621094, d_loss: 0.005795352626591921\n",
      "g_loss: 19.948596954345703, d_loss: 0.01181277446448803\n",
      "g_loss: 19.48894500732422, d_loss: 0.06058048456907272\n",
      "g_loss: 18.296720504760742, d_loss: 0.028993722051382065\n",
      "g_loss: 16.672161102294922, d_loss: 0.16071468591690063\n",
      "g_loss: 18.981346130371094, d_loss: 0.0036772487219423056\n",
      "g_loss: 16.58019256591797, d_loss: 0.02825644239783287\n",
      "g_loss: 21.345779418945312, d_loss: 0.008240483701229095\n",
      "g_loss: 21.628938674926758, d_loss: 0.013165040872991085\n",
      "g_loss: 20.493450164794922, d_loss: 0.004409628454595804\n",
      "g_loss: 17.688282012939453, d_loss: 0.0636730045080185\n",
      "g_loss: 21.24179458618164, d_loss: 0.02700428105890751\n",
      "g_loss: 20.784666061401367, d_loss: 0.0008871806785464287\n",
      "g_loss: 18.47353744506836, d_loss: 0.08370411396026611\n",
      "g_loss: 19.406959533691406, d_loss: 0.005416538566350937\n",
      "g_loss: 19.979068756103516, d_loss: 0.06669360399246216\n",
      "g_loss: 20.79740333557129, d_loss: 0.0070104761980473995\n",
      "g_loss: 18.908451080322266, d_loss: 0.008200010284781456\n",
      "g_loss: 14.496173858642578, d_loss: 0.24037551879882812\n",
      "g_loss: 20.81072998046875, d_loss: 0.009452801197767258\n",
      "g_loss: 20.443906784057617, d_loss: 0.013703828677535057\n",
      "g_loss: 21.03286361694336, d_loss: 0.00913923978805542\n",
      "g_loss: 10.80211353302002, d_loss: 1.684929609298706\n",
      "g_loss: 23.19289779663086, d_loss: 0.020892009139060974\n",
      "g_loss: 21.188356399536133, d_loss: 0.028823111206293106\n",
      "g_loss: 22.15932846069336, d_loss: 0.05530159920454025\n",
      "g_loss: 20.209802627563477, d_loss: 0.04273724555969238\n",
      "g_loss: 22.913782119750977, d_loss: 0.005825018975883722\n",
      "g_loss: 21.343223571777344, d_loss: 0.1293754130601883\n",
      "g_loss: 20.400760650634766, d_loss: 0.026610100641846657\n",
      "g_loss: 19.64767837524414, d_loss: 0.005311910063028336\n",
      "g_loss: 21.03563690185547, d_loss: 0.005820609163492918\n",
      "g_loss: 19.109546661376953, d_loss: 0.006677685771137476\n",
      "g_loss: 21.987442016601562, d_loss: 0.003946668468415737\n",
      "g_loss: 18.159561157226562, d_loss: 0.029408546164631844\n",
      "g_loss: 16.752450942993164, d_loss: 0.021545948460698128\n",
      "g_loss: 19.485265731811523, d_loss: 0.0029395748861134052\n",
      "g_loss: 18.79543685913086, d_loss: 0.035772331058979034\n",
      "g_loss: 20.546424865722656, d_loss: 0.06734812259674072\n",
      "g_loss: 20.20183563232422, d_loss: 0.002529806923121214\n",
      "g_loss: 20.857181549072266, d_loss: 0.000545029528439045\n",
      "g_loss: 18.343303680419922, d_loss: 0.012130009941756725\n",
      "g_loss: 21.96795082092285, d_loss: 0.0012324665440246463\n",
      "g_loss: 17.68317222595215, d_loss: 0.013378201052546501\n",
      "g_loss: 21.289424896240234, d_loss: 0.03813185915350914\n",
      "g_loss: 20.65822410583496, d_loss: 0.03290465846657753\n",
      "g_loss: 25.315818786621094, d_loss: 0.2612699568271637\n",
      "g_loss: 15.266057014465332, d_loss: 0.08852547407150269\n",
      "g_loss: 20.564773559570312, d_loss: 0.0087540652602911\n",
      "g_loss: 18.571367263793945, d_loss: 0.007509610615670681\n",
      "g_loss: 20.09119415283203, d_loss: 0.001680784160271287\n",
      "g_loss: 18.85338020324707, d_loss: 0.006427546497434378\n",
      "g_loss: 19.664325714111328, d_loss: 0.027853840962052345\n",
      "g_loss: 20.450401306152344, d_loss: 0.010631025768816471\n",
      "g_loss: 17.054588317871094, d_loss: 0.057372063398361206\n",
      "g_loss: 20.819625854492188, d_loss: 0.013076284900307655\n",
      "g_loss: 23.552974700927734, d_loss: 0.037481315433979034\n",
      "g_loss: 19.40703582763672, d_loss: 0.058587126433849335\n",
      "g_loss: 19.372583389282227, d_loss: 0.032319076359272\n",
      "g_loss: 21.45428466796875, d_loss: 0.0568464994430542\n",
      "g_loss: 20.615493774414062, d_loss: 0.0038496535271406174\n",
      "g_loss: 19.320232391357422, d_loss: 0.004466496407985687\n",
      "g_loss: 20.008888244628906, d_loss: 0.07765017449855804\n",
      "g_loss: 20.38214874267578, d_loss: 0.012463309802114964\n",
      "g_loss: 18.633323669433594, d_loss: 0.026704514399170876\n",
      "g_loss: 20.337709426879883, d_loss: 0.031979307532310486\n",
      "g_loss: 20.981334686279297, d_loss: 0.0012873189989477396\n",
      "g_loss: 20.31460189819336, d_loss: 0.035072147846221924\n",
      "g_loss: 19.995018005371094, d_loss: 0.004418705590069294\n",
      "g_loss: 19.45058822631836, d_loss: 0.030752375721931458\n",
      "g_loss: 22.56173324584961, d_loss: 0.005189748480916023\n",
      "g_loss: 20.77658462524414, d_loss: 0.03674071282148361\n",
      "g_loss: 21.09747314453125, d_loss: 0.012332422658801079\n",
      "g_loss: 14.966541290283203, d_loss: 0.11285527795553207\n",
      "g_loss: 21.03635025024414, d_loss: 0.009119599126279354\n",
      "g_loss: 22.182680130004883, d_loss: 0.040296491235494614\n",
      "g_loss: 22.4428653717041, d_loss: 0.005204987246543169\n",
      "g_loss: 19.504913330078125, d_loss: 0.023334305733442307\n",
      "g_loss: 21.933837890625, d_loss: 0.14549626410007477\n",
      "g_loss: 18.04873275756836, d_loss: 0.009263446554541588\n",
      "g_loss: 22.205238342285156, d_loss: 0.04260031878948212\n",
      "g_loss: 16.729806900024414, d_loss: 0.07321256399154663\n",
      "g_loss: 23.08660316467285, d_loss: 0.013350807130336761\n",
      "g_loss: 20.423503875732422, d_loss: 0.05049949511885643\n",
      "g_loss: 19.33561134338379, d_loss: 0.03210794925689697\n",
      "g_loss: 19.798397064208984, d_loss: 0.005951766390353441\n",
      "g_loss: 21.569538116455078, d_loss: 0.009225321002304554\n",
      "g_loss: 22.39193344116211, d_loss: 0.01323330495506525\n",
      "g_loss: 18.738269805908203, d_loss: 0.030141837894916534\n",
      "g_loss: 22.823837280273438, d_loss: 0.0022941199131309986\n",
      "g_loss: 63.648799896240234, d_loss: 0.00099463970400393\n",
      "g_loss: 63.29029083251953, d_loss: 0.0008533981745131314\n",
      "g_loss: 72.50053405761719, d_loss: 0.12923060357570648\n",
      "g_loss: 76.53724670410156, d_loss: 0.02887730672955513\n",
      "g_loss: 75.93998718261719, d_loss: 0.08046913892030716\n",
      "g_loss: 89.79832458496094, d_loss: 0.0025262637063860893\n",
      "g_loss: 60.181800842285156, d_loss: 0.000213422768865712\n",
      "g_loss: 55.94181442260742, d_loss: 0.006328766234219074\n",
      "g_loss: 80.33338928222656, d_loss: 0.0026224663015455008\n",
      "g_loss: 29.084753036499023, d_loss: 0.30876949429512024\n",
      "g_loss: 17.129852294921875, d_loss: 0.013103291392326355\n",
      "g_loss: 20.105785369873047, d_loss: 0.007158367894589901\n",
      "g_loss: 21.51995086669922, d_loss: 0.0068526193499565125\n",
      "g_loss: 17.592397689819336, d_loss: 0.03340645134449005\n",
      "g_loss: 20.856849670410156, d_loss: 0.013959110714495182\n",
      "g_loss: 19.718303680419922, d_loss: 0.016071492806077003\n",
      "g_loss: 20.296188354492188, d_loss: 0.01444682665169239\n",
      "g_loss: 19.970752716064453, d_loss: 0.0037409395445138216\n",
      "g_loss: 18.400381088256836, d_loss: 0.01901855133473873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_loss: 19.297653198242188, d_loss: 0.0013786987401545048\n",
      "g_loss: 20.105323791503906, d_loss: 0.013299751095473766\n",
      "g_loss: 15.801603317260742, d_loss: 0.05210685357451439\n",
      "g_loss: 16.94495964050293, d_loss: 0.01418847031891346\n",
      "g_loss: 21.530155181884766, d_loss: 0.01802215352654457\n",
      "g_loss: 21.15152359008789, d_loss: 0.017693180590867996\n",
      "g_loss: 21.13311767578125, d_loss: 0.005852221976965666\n",
      "g_loss: 21.49825096130371, d_loss: 0.08761856704950333\n",
      "g_loss: 19.446779251098633, d_loss: 0.02960270084440708\n",
      "g_loss: 19.836238861083984, d_loss: 0.008750319480895996\n",
      "g_loss: 20.50678253173828, d_loss: 0.07609400898218155\n",
      "g_loss: 21.460098266601562, d_loss: 0.00455390103161335\n",
      "g_loss: 17.350666046142578, d_loss: 0.00364502752199769\n",
      "g_loss: 20.214929580688477, d_loss: 0.00759537611156702\n",
      "g_loss: 19.82906723022461, d_loss: 0.002174539025872946\n",
      "g_loss: 21.104110717773438, d_loss: 0.008721813559532166\n",
      "g_loss: 19.18761444091797, d_loss: 0.007306630257517099\n",
      "g_loss: 21.710411071777344, d_loss: 0.019828718155622482\n",
      "g_loss: 18.20047950744629, d_loss: 0.04720358923077583\n",
      "g_loss: 20.925525665283203, d_loss: 0.08795340359210968\n",
      "g_loss: 19.3333683013916, d_loss: 0.006834585219621658\n",
      "g_loss: 11.103474617004395, d_loss: 1.9283342361450195\n",
      "g_loss: 21.229114532470703, d_loss: 0.003763487096875906\n",
      "g_loss: 23.373619079589844, d_loss: 0.011583401821553707\n",
      "g_loss: 19.16326904296875, d_loss: 0.056030966341495514\n",
      "g_loss: 18.29624366760254, d_loss: 0.06057068705558777\n",
      "g_loss: 13.11073112487793, d_loss: 0.6230748295783997\n",
      "g_loss: 20.86997413635254, d_loss: 0.05442661792039871\n",
      "g_loss: 20.760122299194336, d_loss: 0.002391429152339697\n",
      "g_loss: 20.525625228881836, d_loss: 0.011464085429906845\n",
      "g_loss: 19.53411865234375, d_loss: 0.004398099146783352\n",
      "g_loss: 20.361541748046875, d_loss: 0.0067195831798017025\n",
      "g_loss: 19.783893585205078, d_loss: 0.0006541918846778572\n",
      "g_loss: 16.907989501953125, d_loss: 0.16019128262996674\n",
      "g_loss: 18.226289749145508, d_loss: 0.003363661002367735\n",
      "g_loss: 21.58914566040039, d_loss: 0.010219823569059372\n",
      "g_loss: 21.176441192626953, d_loss: 0.010174477472901344\n",
      "g_loss: 21.214149475097656, d_loss: 0.013610168360173702\n",
      "g_loss: 19.45522689819336, d_loss: 0.09662704169750214\n",
      "g_loss: 20.026676177978516, d_loss: 0.0024015067610889673\n",
      "g_loss: 16.315725326538086, d_loss: 0.020263563841581345\n",
      "g_loss: 17.76436996459961, d_loss: 0.021054895594716072\n",
      "g_loss: 21.7421817779541, d_loss: 0.003879914525896311\n",
      "g_loss: 18.161540985107422, d_loss: 0.04885218292474747\n",
      "g_loss: 19.531808853149414, d_loss: 0.004231470637023449\n",
      "g_loss: 22.090347290039062, d_loss: 0.03206825256347656\n",
      "g_loss: 21.08888816833496, d_loss: 0.0015895552933216095\n",
      "g_loss: 20.598243713378906, d_loss: 0.013241457752883434\n",
      "g_loss: 17.13557243347168, d_loss: 0.12555916607379913\n",
      "g_loss: 20.580415725708008, d_loss: 0.01749960146844387\n",
      "g_loss: 20.274520874023438, d_loss: 0.011141836643218994\n",
      "g_loss: 75.78805541992188, d_loss: 0.0006212492589838803\n",
      "g_loss: 80.45588684082031, d_loss: 0.0009224873501807451\n",
      "g_loss: 69.05906677246094, d_loss: 5.867839354323223e-05\n",
      "g_loss: 83.62579345703125, d_loss: 0.015242932364344597\n",
      "g_loss: 72.02684020996094, d_loss: 0.08210599422454834\n",
      "g_loss: 70.98031616210938, d_loss: 0.07631924003362656\n",
      "g_loss: 67.10014343261719, d_loss: 0.023642389103770256\n",
      "g_loss: 72.17430114746094, d_loss: 0.006170699372887611\n",
      "g_loss: 56.91586685180664, d_loss: 0.00041864148806780577\n",
      "g_loss: 19.411903381347656, d_loss: 0.006743863224983215\n",
      "g_loss: 17.83420753479004, d_loss: 0.005632072687149048\n",
      "g_loss: 21.27242660522461, d_loss: 0.0020203401800245047\n",
      "g_loss: 20.93446159362793, d_loss: 0.0015592859126627445\n",
      "g_loss: 23.072498321533203, d_loss: 0.12830348312854767\n",
      "g_loss: 21.652328491210938, d_loss: 0.004456699825823307\n",
      "g_loss: 10.47750473022461, d_loss: 3.020538806915283\n",
      "g_loss: 22.911514282226562, d_loss: 0.001534374663606286\n",
      "g_loss: 20.47087860107422, d_loss: 0.051706477999687195\n",
      "g_loss: 18.753244400024414, d_loss: 0.05621252954006195\n",
      "g_loss: 18.859291076660156, d_loss: 0.041165322065353394\n",
      "g_loss: 21.27883529663086, d_loss: 0.05929147079586983\n",
      "g_loss: 19.343923568725586, d_loss: 0.00302953296341002\n",
      "g_loss: 20.708656311035156, d_loss: 0.0026595978997647762\n",
      "g_loss: 22.67045021057129, d_loss: 0.004414652939885855\n",
      "g_loss: 22.47344207763672, d_loss: 0.012655828148126602\n",
      "g_loss: 19.576725006103516, d_loss: 0.00493669044226408\n",
      "g_loss: 20.968496322631836, d_loss: 0.009019408375024796\n",
      "g_loss: 17.292171478271484, d_loss: 0.15042294561862946\n",
      "g_loss: 22.336668014526367, d_loss: 0.004598394967615604\n",
      "g_loss: 20.74734115600586, d_loss: 0.006406361237168312\n",
      "g_loss: 19.979944229125977, d_loss: 0.012281140312552452\n",
      "g_loss: 20.628936767578125, d_loss: 0.016001667827367783\n",
      "g_loss: 20.625293731689453, d_loss: 0.00700019858777523\n",
      "g_loss: 22.172277450561523, d_loss: 0.03287970647215843\n",
      "g_loss: 21.64899444580078, d_loss: 0.037419188767671585\n",
      "g_loss: 22.01007080078125, d_loss: 0.01327220257371664\n",
      "g_loss: 21.661518096923828, d_loss: 0.0019577667117118835\n",
      "g_loss: 22.66220474243164, d_loss: 0.1157287210226059\n",
      "g_loss: 19.75639533996582, d_loss: 0.027425268664956093\n",
      "g_loss: 28.40445327758789, d_loss: 1.0147595405578613\n",
      "g_loss: 19.752193450927734, d_loss: 0.0069877635687589645\n",
      "g_loss: 19.92627716064453, d_loss: 0.026932600885629654\n",
      "g_loss: 21.898374557495117, d_loss: 0.006287423428148031\n",
      "g_loss: 16.282302856445312, d_loss: 0.04800652712583542\n",
      "g_loss: 20.684024810791016, d_loss: 0.00445818156003952\n",
      "g_loss: 21.14629364013672, d_loss: 0.14268210530281067\n",
      "g_loss: 19.077844619750977, d_loss: 0.004242343828082085\n",
      "g_loss: 20.735971450805664, d_loss: 0.06435079872608185\n",
      "g_loss: 22.714439392089844, d_loss: 0.012702802196145058\n",
      "g_loss: 24.243555068969727, d_loss: 0.008892642334103584\n",
      "g_loss: 21.119590759277344, d_loss: 0.01751815155148506\n",
      "g_loss: 20.902042388916016, d_loss: 0.01762223243713379\n",
      "g_loss: 24.0642147064209, d_loss: 0.02448725327849388\n",
      "g_loss: 20.479652404785156, d_loss: 0.00520888390019536\n",
      "g_loss: 23.492034912109375, d_loss: 0.013874871656298637\n",
      "g_loss: 24.333656311035156, d_loss: 0.0012233795132488012\n"
     ]
    }
   ],
   "source": [
    "D.train()\n",
    "G.train()\n",
    "for e in range(0, 400):\n",
    "    for real_x, real_y in train_loader:\n",
    "        real_x, real_y = real_x.to(gpu), real_y.float().to(gpu)\n",
    "        G.zero_grad()\n",
    "        z = Variable(torch.randn(bs, 100)).view(-1, 100, 1, 1).to(gpu)\n",
    "        fake_x = G(z)\n",
    "        target_y = copy.deepcopy(real_y).fill_(1)\n",
    "        out = D(fake_x).squeeze()\n",
    "        g_loss = criterion(out, target_y)\n",
    "        g_loss.backward(retain_graph=True)\n",
    "        G_optimizer.step()\n",
    "    \n",
    "        D.zero_grad()\n",
    "        fake_x2 = G(z)\n",
    "        f_out = D(fake_x2).squeeze()\n",
    "        d_fake_loss = criterion(f_out, copy.deepcopy(real_y).fill_(0))\n",
    "        r_out = D(real_x).squeeze()\n",
    "        d_real_loss = criterion(r_out, real_y)\n",
    "        d_loss = d_fake_loss + d_real_loss\n",
    "        d_loss.backward()\n",
    "        D_optimizer.step()\n",
    "    if e % 1 == 0:\n",
    "        print(f\"g_loss: {g_loss.item()}, d_loss: {d_loss.item()}\")\n",
    "    with torch.no_grad():\n",
    "        test_z = Variable(torch.randn(50, 100).view(-1, 100, 1, 1).to(device))\n",
    "        generated = G(test_z)\n",
    "        \n",
    "        out0grid = torchvision.utils.make_grid(generated, nrow=50)\n",
    "        writer.add_image('images', out0grid, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c17707cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9668/3640981455.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mD_optimizer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Acc: {acc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_9668/4234902069.py\u001b[0m in \u001b[0;36mtest_inference\u001b[0;34m(net, testloader)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# Prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "img_size = 64\n",
    "isCrop = False\n",
    "if isCrop:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Scale(108),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "else:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "data_dir = '../gender'          # this path depends on your computer\n",
    "dset = datasets.ImageFolder(data_dir, transform)\n",
    "train_size = int(0.8 * len(dset))\n",
    "test_size = len(dset)- train_size\n",
    "train_set, test_set = random_split(dset, [train_size, test_size])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=bs,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=100,shuffle=False)\n",
    "\n",
    "lr = 0.0002\n",
    "#G = generator(128)\n",
    "D2 = discriminator(128)\n",
    "#G.weight_init(mean=0.0, std=0.02)\n",
    "D2.weight_init(mean=0.0, std=0.02)\n",
    "#G.cuda(gpu)\n",
    "D2.cuda(gpu)\n",
    "\n",
    "criterion = nn.BCELoss().cuda(gpu)\n",
    "#criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "# Adam optimizer\n",
    "#G_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "D_optimizer2 = optim.Adam(D2.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "D2.train()\n",
    "for e in range(600):\n",
    "    for pri_x, pri_y in train_loader:\n",
    "        pri_x, pri_y = pri_x.to(gpu), pri_y.float().to(gpu)#float\n",
    "        D2.zero_grad()\n",
    "        pri_logit = D2(pri_x).squeeze()\n",
    "        loss = criterion(pri_logit, pri_y)\n",
    "        loss.backward()\n",
    "        D_optimizer2.step()\n",
    "    acc, loss = test_inference(D2, test_loader)\n",
    "    if e % 10 == 0:\n",
    "        print(f\"Acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaf1d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
