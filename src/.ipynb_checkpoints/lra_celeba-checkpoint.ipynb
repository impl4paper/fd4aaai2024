{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf602b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import MNIST, EMNIST\n",
    "import torch.nn.functional as F\n",
    "from matplotlib.pyplot import subplots\n",
    "from torchvision.utils import save_image\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "bs = 100\n",
    "n_epoch = 50\n",
    "dim=100\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "writer = SummaryWriter(os.path.join('../celeba', 'test'))\n",
    "gpu = 0\n",
    "device = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4468e850",
   "metadata": {},
   "source": [
    "https://github.com/TomislavZupanovic/Data-Reconstruction/blob/main/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5116aa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\" Generator part of DCGAN model \"\"\"\n",
    "    def __init__(self, latent_vector_size, feature_map, num_channels):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_vector = latent_vector_size\n",
    "        self.feature_map = feature_map\n",
    "        self.channels = num_channels\n",
    "        self.optimizer = None\n",
    "        self.main = None\n",
    "\n",
    "    def build(self):\n",
    "        \"\"\" Builds model with Sequential definition \"\"\"\n",
    "        self.main = nn.Sequential(\n",
    "            # Input is latent vector\n",
    "            nn.ConvTranspose2d(self.latent_vector, self.feature_map * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(self.feature_map * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size: (feature_map*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(self.feature_map * 8, self.feature_map * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.feature_map * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size: (feature_map*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(self.feature_map * 4, self.feature_map * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.feature_map * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size: (feature_map*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(self.feature_map * 2, self.feature_map, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.feature_map),\n",
    "            nn.ReLU(True),\n",
    "            # state size: (feature_map) x 32 x 32\n",
    "            nn.ConvTranspose2d(self.feature_map, self.channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # Output is image: channels x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\" Perform forward pass \"\"\"\n",
    "        return self.main(input)\n",
    "\n",
    "    def define_optim(self, learning_rate, beta1):\n",
    "        self.optimizer = optim.Adam(self.main.parameters(), lr=learning_rate, betas=(beta1, 0.999))\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(layers):\n",
    "        \"\"\" Randomly initialize weights from Normal distribution with mean = 0, std = 0.02 \"\"\"\n",
    "        classname = layers.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            nn.init.normal_(layers.weight.data, 0.0, 0.02)\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            nn.init.normal_(layers.weight.data, 1.0, 0.02)\n",
    "            nn.init.constant_(layers.bias.data, 0)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\" Discriminator part of DCGAN model \"\"\"\n",
    "    def __init__(self, latent_vector_size, feature_map, num_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.latent_vector = latent_vector_size\n",
    "        self.feature_map = feature_map\n",
    "        self.channels = num_channels\n",
    "        self.criterion = None\n",
    "        self.optimizer = None\n",
    "        self.main = None\n",
    "\n",
    "    def build(self):\n",
    "        \"\"\" Builds model with Sequential definition \"\"\"\n",
    "        self.main = nn.Sequential(\n",
    "            # Input is image: channels x 64 x 64\n",
    "            nn.Conv2d(self.channels, self.feature_map, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # State size: (feature_map) x 32 x 32\n",
    "            nn.Conv2d(self.feature_map, self.feature_map * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.feature_map * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # State size: (feature_map * 2) x 16 x 16\n",
    "            nn.Conv2d(self.feature_map * 2, self.feature_map * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.feature_map * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # State size: (feature_map * 4) x 8 x 8\n",
    "            nn.Conv2d(self.feature_map * 4, self.feature_map * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.feature_map * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Output size: (feature_map * 8) x 4 x 4\n",
    "            nn.Conv2d(self.feature_map * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\" Perform forward pass \"\"\"\n",
    "        return self.main(input)\n",
    "\n",
    "    def define_optim(self, learning_rate, beta1):\n",
    "        \"\"\" Initialize Loss Function and Optimizer \"\"\"\n",
    "        self.optimizer = optim.Adam(self.main.parameters(), lr=learning_rate, betas=(beta1, 0.999))\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(layers):\n",
    "        \"\"\" Randomly initialize weights from Normal distribution with mean = 0, std = 0.02 \"\"\"\n",
    "        classname = layers.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            nn.init.normal_(layers.weight.data, 0.0, 0.02)\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            nn.init.normal_(layers.weight.data, 1.0, 0.02)\n",
    "            nn.init.constant_(layers.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd1d20d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.train_dataloader = None\n",
    "        self.test_dataloader = None\n",
    "\n",
    "    def build_dataset(self, image_size, batch_size):\n",
    "        \"\"\" Builds DataLoader for iterating through data \"\"\"\n",
    "        print('\\nBuilding dataset...')\n",
    "        transform = transforms.Compose([transforms.Resize(image_size),\n",
    "                                        transforms.CenterCrop(image_size),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                             (0.5, 0.5, 0.5))])\n",
    "        train_dataset = datasets.ImageFolder(root=self.path + '/train', transform=transform)\n",
    "        test_dataset = datasets.ImageFolder(root=self.path + '/test', transform=transform)\n",
    "        self.train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        self.test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def mask_images(data, option='half'):\n",
    "        \"\"\" Masks the input images with option for 50%, 80% and 90% of image as pixels to reconstruct \"\"\"\n",
    "        valid_options = ('half', 'half_random', '10_random', '20_random', '5_random')\n",
    "        multipliers = {'half': 0.5, 'half_random': 0.5, '10_random': 0.9, '20_random': 0.8, '5_random': 0.95}\n",
    "        if option not in valid_options:\n",
    "            raise ValueError(f\"Option must be one of: {valid_options}\")\n",
    "        real_img = data[0]\n",
    "        img_size = real_img.shape[2]\n",
    "        masked_img, real_part = real_img.clone(), real_img.clone()\n",
    "        masking_equations = [-1.0, -1.0, -1.0]\n",
    "        if option == 'half':\n",
    "            mask = np.zeros(real_img.shape[2:])\n",
    "            mask[:int(img_size / 2), :] = 1\n",
    "            mask = mask.astype('bool')\n",
    "            for equation in masking_equations:\n",
    "                masked_img[:, :, mask] = equation\n",
    "                real_part[:, :, ~mask] = equation\n",
    "        else:\n",
    "            random_array = np.random.choice(2, int(img_size ** 2), p=[1 - multipliers[option], multipliers[option]])\n",
    "            mask = random_array.reshape(real_img.shape[2:]).astype('bool')\n",
    "            for equation in masking_equations:\n",
    "                masked_img[:, :, mask] = equation\n",
    "                real_part[:, :, ~mask] = equation\n",
    "        return masked_img, real_part, mask\n",
    "\n",
    "    @staticmethod\n",
    "    def resize_images(data):\n",
    "        \"\"\" Resize Tensor Images to 4 times lower resolution \"\"\"\n",
    "        real_img = data[0]\n",
    "        resize_images = real_img.clone()\n",
    "        dim_size = int(resize_images.shape[2] / 4)\n",
    "        resize_images = functional.interpolate(resize_images, size=(dim_size, dim_size), mode='bilinear')\n",
    "        return resize_images\n",
    "\n",
    "    def plot_samples(self):\n",
    "        \"\"\" Plots some image samples from dataloader \"\"\"\n",
    "        print('\\nPlotting some image samples...')\n",
    "        # Iterate over data with specified batch_size of 128\n",
    "        images, labels = next(iter(self.train_dataloader))\n",
    "        fig = plt.figure(1, figsize=(15, 5))\n",
    "        for idx in range(10):\n",
    "            # Make plotting grid\n",
    "            ax = fig.add_subplot(2, 10 / 2, idx + 1, xticks=[], yticks=[])\n",
    "            # Use image from dataloader and transform to numpy array\n",
    "            img = images[idx].numpy()\n",
    "            # Transpose image so that last dim is number of channels and un-normalize\n",
    "            transposed_img = np.transpose(img, (1, 2, 0))\n",
    "            image = transposed_img * np.array((0.5, 0.5, 0.5)) + np.array((0.5, 0.5, 0.5))\n",
    "            plt.imshow(image)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5502c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data('../cele_data/celeba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91605854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
