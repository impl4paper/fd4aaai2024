{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44d91c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, random_split,RandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import MNIST, EMNIST\n",
    "import torch.nn.functional as F\n",
    "from matplotlib.pyplot import subplots\n",
    "from torchvision.utils import save_image\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "bs = 128\n",
    "n_epoch = 50\n",
    "dim=100\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "writer = SummaryWriter(os.path.join('../celeimg', 'normaltest4'))\n",
    "gpu = 1\n",
    "device = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4347f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference(net, testloader):\n",
    "    \"\"\" Returns the test accuracy and loss.\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    loss, total, correct = 0.0, 0.0, 0.0\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "    criterion = nn.BCELoss().cuda(gpu)\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(testloader):\n",
    "            images, labels = images.cuda(gpu), labels.float().cuda(gpu)\n",
    "            \n",
    "            # Inference\n",
    "            outputs = net(images).squeeze()\n",
    "            batch_loss = criterion(outputs, labels)\n",
    "            loss += copy.deepcopy(batch_loss.item())\n",
    "\n",
    "            # Prediction\n",
    "            _, pred_labels = torch.max(outputs, 1)\n",
    "            pred_labels = pred_labels.view(-1)\n",
    "            correct += torch.sum(torch.eq(pred_labels, labels)).item()\n",
    "            total += len(labels)\n",
    "    accuracy = correct/total\n",
    "    return accuracy, loss\n",
    "\n",
    "class generator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, d=128):\n",
    "        super(generator, self).__init__()\n",
    "        self.deconv1 = nn.ConvTranspose2d(100, d*8, 4, 1, 0)\n",
    "        self.deconv1_bn = nn.BatchNorm2d(d*8)\n",
    "        self.deconv2 = nn.ConvTranspose2d(d*8, d*4, 4, 2, 1)\n",
    "        self.deconv2_bn = nn.BatchNorm2d(d*4)\n",
    "        self.deconv3 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)\n",
    "        self.deconv3_bn = nn.BatchNorm2d(d*2)\n",
    "        self.deconv4 = nn.ConvTranspose2d(d*2, d, 4, 2, 1)\n",
    "        self.deconv4_bn = nn.BatchNorm2d(d)\n",
    "        self.deconv5 = nn.ConvTranspose2d(d, 3, 4, 2, 1)\n",
    "\n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        # x = F.relu(self.deconv1(input))\n",
    "        x = F.relu(self.deconv1_bn(self.deconv1(input)))\n",
    "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
    "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
    "        x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
    "        x = F.tanh(self.deconv5(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, d=128):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, d, 4, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(d*2)\n",
    "        self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(d*4)\n",
    "        self.conv4 = nn.Conv2d(d*4, d*8, 4, 2, 1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(d*8)\n",
    "        self.conv5 = nn.Conv2d(d*8, 1, 4, 1, 0)# 1-6\n",
    "        #self.linear = nn.Linear(16384, 6)\n",
    "\n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        x = F.leaky_relu(self.conv1(input), 0.2)\n",
    "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n",
    "        #print(x.size())\n",
    "        #x = self.conv5(x)\n",
    "        #print(x.size())\n",
    "        x = F.sigmoid(self.conv5(x))\n",
    "        #x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "912b38cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 19, len： 78390\n",
      "i: 21, len： 84434\n"
     ]
    }
   ],
   "source": [
    "file = r\"../list_attr_celeba.txt\"\n",
    "count = 1\n",
    "#attr_id = [5, 9, 10, 12,18]#光头，黑色，金色，棕色，白色\n",
    "#attr_id = [i for i in range(40)]\n",
    "attr_id = [19,21]#浓状，男\n",
    "imgs = {id: [] for id in attr_id}\n",
    "with open(file, 'r') as f:\n",
    "    for line in f:\n",
    "        if count < 3:\n",
    "            count += 1\n",
    "            continue\n",
    "        else:\n",
    "            attrs = line.strip().split()\n",
    "            for id in attr_id:\n",
    "                if attrs[id]== '1':\n",
    "                    imgs[id].append(attrs[0])\n",
    "                \n",
    "for i in attr_id:\n",
    "#     if len(imgs[i]) > 10000:\n",
    "#         imgs[i] = imgs[i][0: 10000]\n",
    "    print(f\"i: {i}, len： {len(imgs[i])}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27959710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120027\n"
     ]
    }
   ],
   "source": [
    "imgs[9] = imgs[9] +imgs[10] + imgs[12]\n",
    "print(len(imgs[9]))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b09acab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "old_path = r\"../img_align_celeba\"\n",
    "new_path = r\"../f2rf\"\n",
    "resize_size = 64\n",
    "for v in imgs[9]:\n",
    "    new_dir = new_path + \"/1\"\n",
    "    if not os.path.isdir(new_dir):\n",
    "        os.makedirs(new_dir)\n",
    "    \n",
    "    new_file = os.path.join(new_dir, v)\n",
    "    old_file = os.path.join(old_path, v)\n",
    "    img = plt.imread(old_file)\n",
    "    img = resize(img, (resize_size, resize_size))\n",
    "    plt.imsave(fname=new_file, arr=img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dd523b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "old_path = r\"../img_align_celeba\"\n",
    "new_path = r\"../gender\"\n",
    "resize_size = 64\n",
    "for k, v in imgs.items():\n",
    "    new_dir = new_path + \"/\" + str(k)\n",
    "    if not os.path.isdir(new_dir):\n",
    "        os.makedirs(new_dir)\n",
    "    for id in v:\n",
    "        new_file = os.path.join(new_dir, id)\n",
    "        old_file = os.path.join(old_path, id)\n",
    "        img = plt.imread(old_file)\n",
    "        img = resize(img, (resize_size, resize_size))\n",
    "        plt.imsave(fname=new_file, arr=img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11e36e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'19': 0, '21': 1}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_path = r\"../gender\"\n",
    "celeba_data = ImageFolder(new_path)\n",
    "print(celeba_data.class_to_idx)\n",
    "plt.imshow(celeba_data[100][0])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7dadcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 64\n",
    "isCrop = False\n",
    "if isCrop:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Scale(108),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "else:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "data_dir = '../gender'          # this path depends on your computer\n",
    "dset = datasets.ImageFolder(data_dir, transform)\n",
    "#train_size = int(1 * len(dset))\n",
    "#test_size = len(dset)- train_size\n",
    "#train_set, test_set = random_split(dset, [train_size, test_size])\n",
    "train_loader = torch.utils.data.DataLoader(dset, batch_size=bs,shuffle=True, drop_last=True)\n",
    "#test_loader = torch.utils.data.DataLoader(test_set, batch_size=100,shuffle=False)\n",
    "\n",
    "lr = 0.0002\n",
    "G = generator(128)\n",
    "D = discriminator(128)\n",
    "G.weight_init(mean=0.0, std=0.02)\n",
    "D.weight_init(mean=0.0, std=0.02)\n",
    "G.cuda(gpu)\n",
    "D.cuda(gpu)\n",
    "\n",
    "criterion = nn.BCELoss().cuda(gpu)\n",
    "#criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "# Adam optimizer\n",
    "G_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "D_optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91e48002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_loss: 55.201942443847656, d_loss: 1.1175912106864416e-07\n",
      "g_loss: 55.139732360839844, d_loss: 5.587936335871291e-09\n",
      "g_loss: 54.91096496582031, d_loss: 3.725299180246111e-08\n",
      "g_loss: 54.5295524597168, d_loss: 0.0\n",
      "g_loss: 54.3836784362793, d_loss: 1.862645371275562e-09\n",
      "g_loss: 1.5275568962097168, d_loss: 1.2252235412597656\n",
      "g_loss: 1.2991578578948975, d_loss: 0.7269535064697266\n",
      "g_loss: 3.3283724784851074, d_loss: 0.45912593603134155\n",
      "g_loss: 4.506101608276367, d_loss: 0.48710766434669495\n",
      "g_loss: 4.145993709564209, d_loss: 0.1266060173511505\n",
      "g_loss: 3.6287841796875, d_loss: 0.11270797252655029\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15983/2020192689.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0md_real_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_fake_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md_real_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mD_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "D.train()\n",
    "G.train()\n",
    "test_z = Variable(torch.randn(50, 100).view(-1, 100, 1, 1).to(device))\n",
    "real_num = 1\n",
    "fake_num = 0\n",
    "target_num = 1\n",
    "for e in range(0, 400):\n",
    "    for real_x, real_y in train_loader:\n",
    "        real_x, real_y = real_x.to(gpu), real_y.float().to(gpu)\n",
    "        real_label = torch.full((bs,), real_num, device=device).float()\n",
    "        fake_label = torch.full((bs,), fake_num, device=device).float()\n",
    "        \n",
    "        z = Variable(torch.randn(bs, 100)).view(-1, 100, 1, 1).to(gpu)\n",
    "        \n",
    "        G.zero_grad()\n",
    "        fake_x = G(z)\n",
    "        out = D(fake_x).squeeze()\n",
    "        g_loss = criterion(out, real_label)\n",
    "        g_loss.backward()\n",
    "        G_optimizer.step()\n",
    "    \n",
    "        D.zero_grad()\n",
    "        \n",
    "        f_out = D(fake_x.detach()).squeeze()\n",
    "        d_fake_loss = criterion(f_out,fake_label)\n",
    "        r_out = D(real_x).squeeze()\n",
    "        d_real_loss = criterion(r_out, real_label)\n",
    "        d_loss = d_fake_loss + d_real_loss\n",
    "        d_loss.backward()\n",
    "        \n",
    "        D_optimizer.step()\n",
    "    if e % 1 == 0:\n",
    "        print(f\"g_loss: {g_loss.item()}, d_loss: {d_loss.item()}\")\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        generated = G(test_z)\n",
    "        \n",
    "        out0grid = torchvision.utils.make_grid(generated, nrow=50, normalize=True)\n",
    "        writer.add_image('images', out0grid, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c17707cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9668/3640981455.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mD_optimizer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Acc: {acc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_9668/4234902069.py\u001b[0m in \u001b[0;36mtest_inference\u001b[0;34m(net, testloader)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# Prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "img_size = 64\n",
    "isCrop = False\n",
    "if isCrop:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Scale(108),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "else:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "data_dir = '../gender'          # this path depends on your computer\n",
    "dset = datasets.ImageFolder(data_dir, transform)\n",
    "train_size = int(0.8 * len(dset))\n",
    "test_size = len(dset)- train_size\n",
    "train_set, test_set = random_split(dset, [train_size, test_size])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=bs,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=100,shuffle=False)\n",
    "\n",
    "lr = 0.0002\n",
    "#G = generator(128)\n",
    "D2 = discriminator(128)\n",
    "#G.weight_init(mean=0.0, std=0.02)\n",
    "D2.weight_init(mean=0.0, std=0.02)\n",
    "#G.cuda(gpu)\n",
    "D2.cuda(gpu)\n",
    "\n",
    "criterion = nn.BCELoss().cuda(gpu)\n",
    "#criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "# Adam optimizer\n",
    "#G_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "D_optimizer2 = optim.Adam(D2.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "D2.train()\n",
    "for e in range(600):\n",
    "    for pri_x, pri_y in train_loader:\n",
    "        pri_x, pri_y = pri_x.to(gpu), pri_y.float().to(gpu)#float\n",
    "        D2.zero_grad()\n",
    "        pri_logit = D2(pri_x).squeeze()\n",
    "        loss = criterion(pri_logit, pri_y)\n",
    "        loss.backward()\n",
    "        D_optimizer2.step()\n",
    "    acc, loss = test_inference(D2, test_loader)\n",
    "    if e % 10 == 0:\n",
    "        print(f\"Acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaf1d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
